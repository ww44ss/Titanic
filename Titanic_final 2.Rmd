---
title: "Titanic Model Approach"
author: "Winston Saunders"
date: "December 31, 2014"
output: html_document
---

###Introduction

Modeling the kaggle Titanic dataset is a good introduction to several maching learning proactices. The idea is to make a predictive model of survivor. Judging from leaderboards, I want to get to a predictive accuracy of ~ 80%. Let's see how we do. 


To get the data use the following function. The data are stored in my GitHub.

```{r "get data", echo=9:13}

## this section gets the data and loads it into training and testing data files

        
        ## get data sets from github repo
        ## use read data steps from the dude

        library(RCurl)
        readData <- function(path.name, file.name, column.types, missing.types) {
                myData<-getURL(  paste0(path.name, file.name) )
                read.csv(textConnection(myData),
                colClasses=column.types,
                na.strings=missing.types )
                
}

```

The variables for the function are defined as below. 
The train.column.types simplifies the data cleaning for the analysis.

```{r, echo=2:18, warning=FALSE}

        Titanic.path <- "https://raw.githubusercontent.com/ww44ss/Titanic/master/"
        train.data.file <- "train.csv"
        test.data.file <- "test.csv"
        missing.types <- c("NA", "")
        train.column.types <- c('integer',   # PassengerId
                                'factor',    # Survived 
                                'factor',    # Pclass
                                'character', # Name
                                'factor',    # Sex
                                'numeric',   # Age
                                'integer',   # SibSp
                                'integer',   # Parch
                                'character', # Ticket
                                'numeric',   # Fare
                                'character', # Cabin
                                'factor'     # Embarked
        )

        test.column.types <- train.column.types[-2]     # # no Survived column in test.csv
```

Now we can get the data quickly

```{r, echo=3:7}
        setwd("/Users/winstonsaunders/Documents/TitanicKaggle")
        ##Okay let's get the data
        training <- readData(Titanic.path, train.data.file, train.column.types, missing.types)
        testing <-  readData(Titanic.path, test.data.file, test.column.types, missing.types)

        trainingRaw<-training
        testingRaw<-testing

```


##Model One

Let's look at the data using the Amelia Package

```{r, echo=FALSE, fig.align='center'}

        ## map missing data by provided feature
        require(Amelia)
        missmap(training, main="Titanic Training Data - Missings Map", 
                col=c("wheat", "darkorange4"), legend=FALSE, y.cex=1)


```

We can explore the data by looking at quick snapshot

```{r, warning=FALSE}
library(GGally)

ggpairs(training[c(2, 3, 5, 6)])

```

Since there are many NA's in the age data let's try replacing those with the mean ages for male or females.  
  
```{r "clean data1", echo=FALSE}

  ## Clean the data

        ## calculate the median age for the population, men and women
        meanAge<-mean(training$Age[is.na(training$Age)==FALSE])

        meanMaleAge<-median(training$Age[training$Sex=="male"&is.na(training$Age)==FALSE])
        meanFemaleAge<-median(training$Age[training$Sex=="female"&is.na(training$Age)==FALSE])

        ## substitute median ages based on sex
        
        training$Age[is.na(training$Age)&training$Sex=="male"]<-meanMaleAge
        training$Age[is.na(training$Age)&training$Sex=="female"]<-meanFemaleAge


        testing$Age[is.na(testing$Age)&testing$Sex=="male"]<-meanMaleAge
        testing$Age[is.na(testing$Age)&testing$Sex=="female"]<-meanFemaleAge


```

The median male age is `r round(meanMaleAge, 1)` years and the median female age is `r round(meanFemaleAge,1)` years. Here is a snapshot of the cleaned data.  Note the fractional year on substituted values. 

```{r "feature engineering"}

training$model<-training$Survived
training$model<-0

training$model[training$Sex=="female"]<-1
training$model[training$Age<10 & training$Sex=="male"]<-1
training$model[(training$Parch+training$SibSp)>3]<-0
#training$model[training$Age>60]<-1

testing$model<-testing$Survived
testing$model<-0

testing$model[testing$Sex=="female"]<-1
testing$model[testing$Age<10 & testing$Sex=="male" ]<-1
testing$model[(testing$Parch+testing$SibSp)>3]<-0
#testing$model[testing$Age>60]<-1

```


The first model looks at the following function.

```{r "First model", warning=FALSE, echo=33, message=FALSE}

#

        t<-table(training$model, training$Survived)

        acc<-(t[1,1]+t[2,2])/(t[1,1]+t[2,2]+t[1,2]+t[2,1])


```
use a glm of family "Binomial"

Here is the confusion table

```{r}
t


acc

```
 

```{r "output One", echo=11}
        
        ## Make model prediciton
        

        ## factor into choices
        
        Survived<-testing$model
        PassengerId<-testing$PassengerId

        ## Write output file
        Output<-cbind(PassengerId, Survived)
        write.csv(Output, "Model2.csv", row.names=FALSE)


```

This model has a kaggle accuracy of 0.77033



