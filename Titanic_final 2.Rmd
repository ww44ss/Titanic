---
title: "Titanic Model Approach"
author: "Winston Saunders"
date: "December 31, 2014"
output: html_document
---

###Introduction

This is a model for the kaggle Titanic dataset. The idea is to make a predictive model of survivor. Judging from leaderboards, I need to get to predictive accuracy of ~ 80%. Let's see how we do. 


To get the data use the following function. The data are stored in my GitHub.

```{r "get data", echo=9:13}

## this section gets the data and loads it into training and testing data files

        
        ## get data sets from github repo
        ## use read data steps from the dude

        library(RCurl)
        readData <- function(path.name, file.name, column.types, missing.types) {
                myData<-getURL(  paste0(path.name, file.name) )
                read.csv(textConnection(myData),
                colClasses=column.types,
                na.strings=missing.types )
                
}

```

The variables for the function are defined as below. 
The train.column.types simplifies the data cleaning for the analysis.

```{r, echo=2:18, warning=FALSE}

        Titanic.path <- "https://raw.githubusercontent.com/ww44ss/Titanic/master/"
        train.data.file <- "train.csv"
        test.data.file <- "test.csv"
        missing.types <- c("NA", "")
        train.column.types <- c('integer',   # PassengerId
                                'factor',    # Survived 
                                'factor',    # Pclass
                                'character', # Name
                                'factor',    # Sex
                                'numeric',   # Age
                                'integer',   # SibSp
                                'integer',   # Parch
                                'character', # Ticket
                                'numeric',   # Fare
                                'character', # Cabin
                                'factor'     # Embarked
        )

        test.column.types <- train.column.types[-2]     # # no Survived column in test.csv
```

Now we can get the data quickly

```{r, echo=3:7}
        setwd("/Users/winstonsaunders/Documents/TitanicKaggle")
        ##Okay let's get the data
        training <- readData(Titanic.path, train.data.file, train.column.types, missing.types)
        testing <-  readData(Titanic.path, test.data.file, test.column.types, missing.types)

        trainingRaw<-training
        testingRaw<-testing

```


##Model One

Let's look at the data using the Amelia Package

```{r, echo=FALSE, fig.align='center'}

        ## map missing data by provided feature
        require(Amelia)
        missmap(training, main="Titanic Training Data - Missings Map", 
                col=c("wheat", "darkorange4"), legend=FALSE, y.cex=1)


```

We can explore the data by looking at quick snapshot

```{r, warning=FALSE}
library(GGally)

ggpairs(training[c(2, 3, 5, 6)])

```

Since there are many NA's in the age data let's try replacing those with the mean ages for male or females.  
  
```{r "clean data1", echo=FALSE}

  ## Clean the data

        ## calculate the median age for the population, men and women
        meanAge<-mean(training$Age[is.na(training$Age)==FALSE])

        meanMaleAge<-median(training$Age[training$Sex=="male"&is.na(training$Age)==FALSE])
        meanFemaleAge<-median(training$Age[training$Sex=="female"&is.na(training$Age)==FALSE])

        ## substitute median ages based on sex
        
        training$Age[is.na(training$Age)&training$Sex=="male"]<-meanMaleAge
        training$Age[is.na(training$Age)&training$Sex=="female"]<-meanFemaleAge


        testing$Age[is.na(testing$Age)&testing$Sex=="male"]<-meanMaleAge
        testing$Age[is.na(testing$Age)&testing$Sex=="female"]<-meanFemaleAge


```

The median male age is `r round(meanMaleAge, 1)` years and the median female age is `r round(meanFemaleAge,1)` years. Here is a snapshot of the cleaned data.  Note the fractional year on substituted values. 

```{r "feature engineering"}

training$VeryYoung <- 0
training$VeryYoung[training$Age<18]<-1

testing$VeryYoung<-0
testing$VeryYoung[testing$Age<18]<-1


training$Man <- 0
training$Man[training$Age>18 & training$Age < 30 ]<-1

testing$Man<-0
testing$Man[testing$Age>18& testing$Age < 30 ]<-1




```


```{r}
training[1:12,c("Survived", "Age", "Sex", "Pclass", "VeryYoung", "Man")]
```

The first model looks at the following function.

```{r "First model", warning=FALSE, echo=33, message=FALSE}

## This is a first simple model


      ## create data sub partition

        require(caret)
        set.seed(8675309)
        xx <- createDataPartition(y=training$Survived, p=0.75, list=FALSE)
 

        ##Define training and test sets

        train1<-training[xx,]
        test1<-training[-xx,]

        ## set up training control

        control1 <- trainControl(method = "cv")

        ## model using random forest

        modelfunction<-Survived~Age +Pclass+Sex+factor(VeryYoung)+factor(Man)

        model1 <- train(modelfunction, data = train1, family="rf" )

        prediction1 <- predict(model1, test1)

        t<-table(prediction1, test1$Survived)

        conf<-confusionMatrix(test1$Survived, prediction1)


```
use a glm of family "Binomial"

Here is the confusion table

```{r}
t


model1
```
 
The estimated accuracy is `r round(100*conf$overall[1],5)`%.

```{r "output One", echo=11}
        
        ## Make model prediciton
        predictionT <- predict(model1, testing)

        ## factor into choices
        
        Survived<-as.numeric(predictionT)-1
        PassengerId<-testing$PassengerId

        ## Write output file
        Output<-cbind(PassengerId, Survived)
        write.csv(Output, "Model2.csv", row.names=FALSE)


```

This model has a kaggle accuracy of 0.74641



