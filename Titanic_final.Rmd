---
title: "Titanic"
author: "Winston Saunders"
date: "December 31, 2014"
output: html_document
---

###Introduction

This is a model for the kaggle Titanic dataset. The idea is to make a predictive model of survivor. Judging from leaderboards, 


```{r "get data", echo=9:10}

## this section gets the data and loads it into training and testing data files

        ##set working directory

        setwd("/Users/winstonsaunders/Documents/TitanicKaggle")

        ## get data sets
        training <- read.csv("train.csv", na.strings=c("NA", ""))
        testing <- read.csv("test.csv", na.strings=c("NA", ""))

        trainingRaw<-training
        testingRaw<-testing

```




##Model One

Base first model on Sex and Age per tutorial. Since there are many NA's in the data we replace those with the mean ages for male or females.  
  
The model is trained with a _Random Forest_. 

```{r "clean data1", echo=FALSE}

  ## Clean the data

        ## calculate the median age for the population, men and women
        meanAge<-mean(training$Age[is.na(training$Age)==FALSE])

        meanMaleAge<-mean(training$Age[training$Sex=="male"&is.na(training$Age)==FALSE])
        meanFemaleAge<-mean(training$Age[training$Sex=="female"&is.na(training$Age)==FALSE])

        ## substitute median ages based on sex
        
                training$Age[is.na(training$Age)&training$Sex=="male"]<-meanMaleAge
                training$Age[is.na(training$Age)&training$Sex=="female"]<-meanFemaleAge


                testing$Age[is.na(testing$Age)&testing$Sex=="male"]<-meanMaleAge
                testing$Age[is.na(testing$Age)&testing$Sex=="female"]<-meanFemaleAge


```
The mean male age is `r round(meanMaleAge, 1)` years and the mean female age is `r round(meanFemaleAge,1)` years. Here is a snapshot of the cleaned data.  Note the fractional year on substituted values. 

```{r}
training[1:6,c("Survived", "Age", "Sex")]
```

The first model looks at the following function

```{r "First model", warning=FALSE, echo=33, message=FALSE}

## This is a first simple model


      ## create data sub partition

        require(caret)
        set.seed(8675307)
        xx <- createDataPartition(y=training$Survived, p=0.80, list=FALSE)
   


        ##Define training and test sets

        train1<-training[xx,]
        test1<-training[-xx,]

        #train1 <- train1[,c("Survived","Sex", "Age")]
        #test1 <-   test1[,c("Survived","Sex", "Age")]


        ## simplify Age column by bucketing
        ## group in multiples of 5*n+1 (1, 6, 11, ...)
        ## train1$Age2 <- 16*round(train1$Age/16,0)
        ## test1$Age2 <- 16*round(test1$Age/16,0)

        ## set up training control

        control1 <- trainControl(method = "cv")

        ## model using random forest

        modelfunction<-Survived~Age+Sex

        model1 <- train(modelfunction, data = train1, method="rf", trControl = control1, prox=FALSE)

        prediction1 <- predict(model1, test1)

        ## assign to zero or one. 

        prediction1[prediction1<0.75]<-0
        prediction1[prediction1>=0.75]<-1
        prediction1<-as.factor(prediction1)

        t<-table(prediction1, test1$Survived)

        conf<-confusionMatrix(test1$Survived, prediction1)


```

Here is the confusion table

```{r}
conf$table
```
 
The accuracy is `r round(100*conf$overall[1],1)`%.

##Model One Point Five

Let's look at Fare and Age


```{r "look at data one five", fig.align='center', echo=FALSE, warning=FALSE, message=FALSE}

        ## a key observation is that replacing age is a key swing point.
        ## survival <- age <- lots of blanks <- pay more attention here

        ## restore original data
        training<-trainingRaw
        testing<-testingRaw


        require(caret)
        set.seed(8675307)
        xx <- createDataPartition(y=training$Survived, p=0.90, list=FALSE)
  
        ##Define training and test sets

        train1<-training[xx,]
        test1<-training[-xx,]

        train1$Fare<-as.numeric(train1$Fare)
        test1$Fare<-as.numeric(test1$Fare)



```

```{r "Simple model", echo=FALSE, fig.align='center'}

        ## Make sure there are no zero fares
        train1$Fare[train1$Fare==0]<-mean(train1$Fare)
        test1$Fare[test1$Fare==0]<-mean(test1$Fare)

        ## Treat testing Fare data
        testing$Fare[testing$Fare==0]<-mean(testing$Fare)
        
        ## Plot cleaned data
        require(ggplot2)
        p<-ggplot(train1, aes(Fare, Survived)) + geom_point()
        p<-p+facet_grid(.~Sex)
        p <- p + scale_x_log10()
        p<-p+ggtitle("Fare and Survived / Sex")
        p   

```

```{r, "age Fix one five", echo=6,warning=FALSE}

        ## to create model first get rid of NA rows in Age
        trainfull<-train1[is.na(train1$Age)==FALSE, ]
        testfull<-test1[is.na(train1$Age)==FALSE, ]
        ## fit model dependent on Pclass and Sex
        agemodel<-glm(Age~Pclass+Sex, data=trainfull)
        
        ## First make an extra column of predicted values

                ageTestPredict<-predict(agemodel, test1)
                test1$AgeModel<-ageTestPredict

                ageTrainPredict<-predict(agemodel, train1)
                train1$AgeModel<-ageTrainPredict


                ageTestingPredict<-predict(agemodel, testing)
                testing$AgeModel<-ageTestingPredict


        ## Fill in NA's with Model values

                train1[is.na(train1$Age)==TRUE,"Age"]<-train1[is.na(train1$Age)==TRUE,"AgeModel"]
                test1[is.na(test1$Age)==TRUE,"Age"]<-test1[is.na(test1$Age)==TRUE,"AgeModel"]

        ## treat testing data
                testing[is.na(testing$Age)==TRUE,"Age"]<-testing[is.na(testing$Age)==TRUE,"AgeModel"]
```

```{r "Prediction one five", echo=6, warning=FALSE, fig.align='center' }


        control1 <- trainControl(method = "cv")

        ## calculate logs of Fare data
        train1$logFare<-log10(train1$Fare)
        test1$logFare<-log10(test1$Fare)


        testing$logFare<-log10(testing$Fare)
        
        ## the model function
        modelfunction <- Survived~Age+factor(Sex)+factor(Pclass)+logFare

        ## model using random forest
        model1 <- train(modelfunction, data = train1, method="rf", trControl = control1, prox=FALSE)

        prediction1 <- predict(model1, test1)

        

```
A histogram of the predictions and a graph of the results is shows reasonable accuracy.  
 
```{r "plotz one five", echo=FALSE, fig.align='center'}

        hist(prediction1)

        test1x<-cbind(prediction1, test1)

        p <- ggplot(test1x, aes(Survived, prediction1, color=Sex)) + geom_boxplot()
        p <- p+ facet_grid(.~Pclass)
        p <- p+ ggtitle("Prediction vs. Survived / Pclass")
        p 
   

        prediction1[prediction1<0.65]<-0
        prediction1[prediction1>=0.65]<-1
        prediction1<-as.factor(prediction1)


        conf2<-confusionMatrix(test1$Survived, prediction1)

```


```{r "output", echo=11}
        
        ## Make model prediciton
        predictionT <- predict(model1, testing)

        ## factor into choices
        predictionT[predictionT<0.65]<-0
        predictionT[predictionT>=0.65]<-1
        Survived<-predictionT
        PassengerId<-testing$PassengerId

        ## Write output file
        Output<-cbind(PassengerId, Survived)
        write.csv(Output, "Model2.csv", row.names=FALSE)

```

Resulting in the following confusion matrix  
```{r, echo=FALSE}
conf2$table
```

The accuracy is `r round(100*conf2$overall[1],2)` versus earlier `r round(100*conf$overall[1],2)`%.



