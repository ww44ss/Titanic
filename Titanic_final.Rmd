---
title: "Titanic Model Approach"
author: "Winston Saunders"
date: "December 31, 2014"
output: html_document
---

###Introduction

This is a model for the kaggle Titanic dataset. The idea is to make a predictive model of survivor. Judging from leaderboards, I need to get to predictive accuracy of ~ 80%. Let's see how we do. 


To get the data use the following function. The data are stored in my GitHub.

```{r "get data", echo=9:13}

## this section gets the data and loads it into training and testing data files

        
        ## get data sets from github repo
        ## use read data steps from the dude

        library(RCurl)
        readData <- function(path.name, file.name, column.types, missing.types) {
                myData<-getURL(  paste0(path.name, file.name) )
                read.csv(textConnection(myData),
                colClasses=column.types,
                na.strings=missing.types )
                
}

```

The variables for the function are defined as below. 
The train.column.types simplifies the data cleaning for the analysis.

```{r, echo=2:18, warning=FALSE}

        Titanic.path <- "https://raw.githubusercontent.com/ww44ss/Titanic/master/"
        train.data.file <- "train.csv"
        test.data.file <- "test.csv"
        missing.types <- c("NA", "")
        train.column.types <- c('integer',   # PassengerId
                                'factor',    # Survived 
                                'factor',    # Pclass
                                'character', # Name
                                'factor',    # Sex
                                'numeric',   # Age
                                'integer',   # SibSp
                                'integer',   # Parch
                                'character', # Ticket
                                'numeric',   # Fare
                                'character', # Cabin
                                'factor'     # Embarked
        )

        test.column.types <- train.column.types[-2]     # # no Survived column in test.csv
```

Now we can get the data quickly

```{r, echo=3:7}

        ##Okay let's get the data
        training <- readData(Titanic.path, train.data.file, train.column.types, missing.types)
        testing <-  readData(Titanic.path, test.data.file, test.column.types, missing.types)

        trainingRaw<-training
        testingRaw<-testing

```


##Model One

Let's look at the data using the Amelia Package

```{r, echo=FALSE, fig.align='center'}

        ## map missing data by provided feature
        require(Amelia)
        missmap(training, main="Titanic Training Data - Missings Map", 
                col=c("wheat", "darkorange4"), legend=FALSE, y.cex=1)


```

We can explore the data by looking at quick snapshot

```{r, warning=FALSE}
library(GGally)

ggpairs(training[c(2, 3, 5, 6)])

```

Since there are many NA's in the age data let's try replacing those with the mean ages for male or females.  
  
```{r "clean data1", echo=FALSE}

  ## Clean the data

        ## calculate the median age for the population, men and women
        meanAge<-mean(training$Age[is.na(training$Age)==FALSE])

        meanMaleAge<-median(training$Age[training$Sex=="male"&is.na(training$Age)==FALSE])
        meanFemaleAge<-median(training$Age[training$Sex=="female"&is.na(training$Age)==FALSE])

        ## substitute median ages based on sex
        
        training$Age[is.na(training$Age)&training$Sex=="male"]<-meanMaleAge
        training$Age[is.na(training$Age)&training$Sex=="female"]<-meanFemaleAge


        testing$Age[is.na(testing$Age)&testing$Sex=="male"]<-meanMaleAge
        testing$Age[is.na(testing$Age)&testing$Sex=="female"]<-meanFemaleAge


```

The median male age is `r round(meanMaleAge, 1)` years and the median female age is `r round(meanFemaleAge,1)` years. Here is a snapshot of the cleaned data.  Note the fractional year on substituted values. 

```{r}

training$VeryYoung <- 0
training$VeryYoung[training$Age<10.1]<-1
```


```{r}
training[1:6,c("Survived", "Age", "Sex", "Pclass", "VeryYoung")]
```

The first model looks at the following function

```{r "First model", warning=FALSE, echo=33, message=FALSE}

## This is a first simple model


      ## create data sub partition

        require(caret)
        set.seed(8675309)
        xx <- createDataPartition(y=training$Survived, p=0.75, list=FALSE)
   


        ##Define training and test sets

        train1<-training[xx,]
        test1<-training[-xx,]

        ## set up training control

        control1 <- trainControl(method = "cv")

        ## model using random forest

        modelfunction<-Survived~Pclass+Sex+factor(VeryYoung)

        model1 <- train(modelfunction, data = train1, method="rf", trControl = control1, prox=FALSE)

        prediction1 <- predict(model1, test1)

        t<-table(prediction1, test1$Survived)

        conf<-confusionMatrix(test1$Survived, prediction1)


```

Here is the confusion table

```{r}
conf$table
```
 
The accuracy is `r round(100*conf$overall[1],1)`%.

##Model One Point Five

Let's look at The dependence of Fare, Age, and Sex


```{r "look at data one five", fig.align='center', echo=FALSE, warning=FALSE, message=FALSE}

        ## a key observation is that replacing age is a key swing point.
        ## survival <- age <- lots of blanks <- pay more attention here

        ## restore original data
        training<-trainingRaw
        testing<-testingRaw


        require(caret)
        set.seed(8675307)
        xx <- createDataPartition(y=training$Survived, p=0.75, list=FALSE)
  
        ##Define training and test sets

        train1<-training[xx,]
        test1<-training[-xx,]

        train1$Fare<-as.numeric(train1$Fare)
        test1$Fare<-as.numeric(test1$Fare)



```

```{r "Simple model", echo=FALSE, fig.align='center'}

        ## Make sure there are no zero fares
        train1$Fare[train1$Fare==0]<-mean(train1$Fare)
        test1$Fare[test1$Fare==0]<-mean(test1$Fare)

        ## Treat testing Fare data
        testing$Fare[testing$Fare==0]<-mean(testing$Fare)
        
        ## Plot cleaned data
        require(ggplot2)
        p<-ggplot(train1, aes(Fare, Survived)) + geom_point()
        p<-p+facet_grid(.~Sex)
        p <- p + scale_x_log10()
        p<-p+ggtitle("Fare and Survived / Sex")
        p   

```

```{r, "age Fix one five", echo=6,warning=FALSE}

        ## to create model first get rid of NA rows in Age
        trainfull<-train1[is.na(train1$Age)==FALSE, ]
        testfull<-test1[is.na(train1$Age)==FALSE, ]
        ## fit model dependent on Pclass and Sex
        agemodel<-glm(Age~Pclass+Sex, data=trainfull)
        
        ## First make an extra column of predicted values

                ageTestPredict<-predict(agemodel, test1)
                test1$AgeModel<-ageTestPredict

                ageTrainPredict<-predict(agemodel, train1)
                train1$AgeModel<-ageTrainPredict


                ageTestingPredict<-predict(agemodel, testing)
                testing$AgeModel<-ageTestingPredict


        ## Fill in NA's with Model values

                train1[is.na(train1$Age)==TRUE,"Age"]<-train1[is.na(train1$Age)==TRUE,"AgeModel"]
                test1[is.na(test1$Age)==TRUE,"Age"]<-test1[is.na(test1$Age)==TRUE,"AgeModel"]

        ## treat testing data
                testing[is.na(testing$Age)==TRUE,"Age"]<-testing[is.na(testing$Age)==TRUE,"AgeModel"]
```

```{r "Prediction one five", echo=6, warning=FALSE, fig.align='center' }


        control1 <- trainControl(method = "cv")

        ## calculate logs of Fare data
        train1$logFare<-log10(train1$Fare)
        test1$logFare<-log10(test1$Fare)


        testing$logFare<-log10(testing$Fare)
        
        ## the model function
        modelfunction <- Survived~Age+Sex+Pclass+logFare

        ## model using random forest
        model1 <- train(modelfunction, data = train1, method="rf", trControl = control1, prox=FALSE)

        prediction1 <- predict(model1, test1)

        

```
A histogram of the predictions and a graph of the results is shows reasonable accuracy.  
 
```{r "plotz one five", echo=FALSE, fig.align='center'}

        #hist(prediction1)

        test1x<-cbind(prediction1, test1)

        p <- ggplot(test1x, aes(Survived, prediction1, color=Sex)) + geom_boxplot()
        p <- p+ facet_grid(.~Pclass)
        p <- p+ ggtitle("Prediction vs. Survived / Pclass")
        p 
   

        #prediction1[prediction1<0.65]<-0
        #prediction1[prediction1>=0.65]<-1
        #prediction1<-as.factor(prediction1)


        conf2<-confusionMatrix(test1$Survived, prediction1)

```


```{r "output", echo=11}
        
        ## Make model prediciton
        predictionT <- predict(model1, testing)

        ## factor into choices
        #predictionT[predictionT<0.65]<-0
        #predictionT[predictionT>=0.65]<-1
        Survived<-predictionT
        PassengerId<-testing$PassengerId

        ## Write output file
        Output<-cbind(PassengerId, Survived)
        write.csv(Output, "Model2.csv", row.names=FALSE)

```

Resulting in the following confusion matrix  
```{r, echo=FALSE}
conf2$table
```

The accuracy is `r round(100*conf2$overall[1],2)` versus earlier `r round(100*conf$overall[1],2)`%.



